\chapter{Webanalyse} %ca 8-10 Seiten
\label{ch:webanalyse} 

\section{Definitionen und Abgrenzung} % 1-1,5 Seiten
Die Webanalyse (engl. Web Analytics) ist ein Teilgebiet der Digitalanalyse (engl. Digital Analytics) und hat als Aufgabe, Webseiten zu analysieren und zu optimieren. Die Abgrenzung zwischen Webanalyse und Digitalanalyse zeigt, dass sich die Webanalyse primär auf Daten bezieht, die aus dem Besuch und der Nutzung von Websites entstehen, wobei die Digitalanalyse den Rahmen erweitert und sich mit der kanalfübergreifenden Ermittlung von Nutzerbezogenen Daten beschäftigt [Hassler, 2019, Kap.1.2]. Die Webanalyse wird von der Web Analytics Association (WAA) wie folgt definiert: \textit{``Web Analytics is the measurement, collection, analysis and reporting of Internet data for the purposes of understanding and optimizing Web usage.''} [WAA, 2008, S.3].

Eine weitere Definition liefert die ISO 19731:2017, welche Webanalyse als Analyse und Berichterstattung über das Verhalten, Aussagen und Stimmungen von Nutzern auf Online-Plattformen beschreibt [International Organization for Standardization (ISO), 2017, Kap.3.40]. Diese Definition verdeutlicht noch einmal die Bedeutung von qualitativen und stimmungsbasierten Daten bei der Webanalyse. 

Sie dient unter anderem dazu, die Herkunft von Nutzern (Kanäle), deren Klickverhalten (Klickpfade) sowie die Effektivität von Kampagnen und die Leistung einer Website zu analysieren. Erkenntnisse aus der Webanalyse unterstützen Unternehmen oder Organisationen dabei, ihre Inhalte entsprechend des Nutzerverhaltens zu personalisieren, Schwachstellen in der Customer Journey zu identifizieren und die Nutzererfahrung (User Experience) zu verbessern.

-> Abgrenzung von Webanalyse und Webmonitoring
-> Es gibt viele Bezeichnungen für die Webanalyse.. Digital Analytics, Webanalytics usw... im weiteren Verlauf der Arbeit sollen einfachheitshalber diese Begriffe alle unter der Bezeichnung Webanalyse verschmolzen werden 

\section{Ziele} %1,5 Seiten
Die Webanalyse im Allgemeinem hat das Ziel, auf Grundlage von Daten Erkenntnisse zur Optimierung digitaler Kanäle zu gewinnen. Dabei ist jedoch zu berücksichtigen, dass die Webanalyse keine exakte Wissenschaft ist. Zum Beispiel unterliegen Daten zur Nutzeraktivität, wie Besucher- und Nutzungszahlen, unvermeidbaren Ungenauigkeiten, welche bereits bei der Erhebung und Verarbeitung entstehen können. Fragen nach der genauen Messung aller Besucher, der Unterscheidung von menschlichen und automatisierten Zugriffen sowie der Interpretation von Nutzungsverhalten verdeutlichen die Grenzen dieser Methode. Dennoch liegt der Fokus nicht auf absoluter Präzision, sondern auf der Ableitung verwertbarer Trends und Veränderungen, etwa durch prozentuale Vergleiche. Dieser pragmatische Ansatz ermöglicht es, relevante Erkenntnisse für die Optimierung digitaler Angebote zu gewinnen, ohne dabei auf vollständige Genauigkeit angewiesen zu sein [Hassler, 2019, Kap.1.4].

Der Zweck der Analyse des Bildungsportals \textsc{evaschiffmann.de} ist es zunächst, einen Überblick über das aktuelle Nutzerverhalten auf dem Bildungsportal zu bekommen. Dies umfasst sowohl die Identifikation der am häufigsten genutzten Inhalte und Funktionen als auch die Ermittlung möglicher Schwachstellen in der Benutzerführung. Dadurch können gezielte Maßnahmen abgeleitet werden, um die Effektivität und Attraktivität des Portals nachhaltig zu steigern. Somit kann die Lösung ebenfalls dafür verwendet werden folgende Ziele zu erreichen: 
\begin{enumerate}
    \item \textbf{Verbesserung der Lernprozesse:}
    Durch die Analyse von Webdaten können Bildungsportale herausfinden, welche Inhalte von Nutzern effektiv genutzt werden und welche weniger relevant sind. Dies ermöglicht eine gezielte Optimierung der Lerninhalte und eine Anpassung an die Bedürfnisse der Lernenden (Piwik PRO, o. J.).
    \item \textbf{Steigerung der Benutzerfreundlichkeit:}
    Die Untersuchung von Nutzerinteraktionen erlaubt es, die Benutzeroberfläche so zu gestalten, dass sie einfacher zu bedienen ist und den Lernprozess unterstützt. Dies trägt zu einer besseren Lernerfahrung bei und erleichtert die Navigation auf der Plattform (Piwik PRO, o. J.).
    \item \textbf{Personalisierung des Lernens:}
    Daten aus der Webanalyse ermöglichen es, individuelle Lernpfade zu entwickeln, die an die Fähigkeiten und Bedürfnisse einzelner Nutzer angepasst sind. Dies sorgt für eine effektivere und nachhaltigere Lernerfahrung (StudySmarter, o. J.).
    \item \textbf{Identifikation von Schwachstellen:} Die Analyse der Interaktionen und Nutzungsdaten kann Schwachstellen in der Customer Journey aufdecken, die anschließend gezielt beseitigt werden können, um die Lernerfahrung weiter zu optimieren (Piwik PRO, o. J.).
\end{enumerate} 

Der erste Schritt zur Erreichung dieser Ziele ist es, eine fundierte Grundlage zu schaffen, um Optimierungspotenziale zu identifizieren und Fortschritte zu messen. Hierbei spielt die Auswahl geeigneter Metriken, Kennzahlen und Key Performance Indicators (KPIs) eine entscheidende Rolle. Sie ermöglichen es, die Interaktionen mit dem Bildungsportal quantifierbar zu machen, um datenbasierte Entscheidungen treffen zu können. Im folgenden Kapitel werden die wichtigsten Metriken, Kennzahlen und KPIs, sowie deren Bedeutung näher erläutert. (Quelle?)

\section{Metriken, Kennzahlen und KPIs} % 1-2
\label{sec:kpis}
Um die im vorherigen Kapitel beschriebenen Ziele zu erreichen, sollen im Folgenden die relevanten Indikatoren, welche ein Verständnis über das Nutzerverhalten schaffen sollen näher erläutert werden. Zunächst ist es allerdings erst einmal notwendig die Begriffe \textbf{"Metrik"}, \textbf{"Kennzahl"} und \textbf{"Key Performance Indicator (KPI)"} zu definieren und voneinander abzugrenzen.

Eine \textbf{Metrik} ist ein Rohwert, der bestimmte Aspekte quantifiziert, wie beispielsweise die Anzahl der Klicks auf einer Website. Metriken dienen als Grundlage für weiterführende Analysen, liefern jedoch keine kontextbezogenen Aussagen. [Lammenett, 2019, S.10].

Eine \textbf{Kennzahl} baut auf Metriken auf, indem sie diese interpretiert und in einen spezifischen Zusammenhang stellt. Beispiele hierfür sind die Absprungrate oder auch eine Konversionsrate. Sie ermöglichen eine erste Bewertung, bleiben jedoch ohne eine klare Zieldefinition begrenzt in ihrer Aussagekraft. [Lammenett, 2019, S.10;S.20;S.27].

Ein \textbf{Key Performance Indicator (KPI)}entsteht, wenn eine Kennzahl mit einem konkreten Ziel verknüpft wird. Diese Zielbindung macht aus der Kennzahl einen strategischen Indikator, der zeigt, wie effektiv bestimmte Maßnahmen sind oder wie gut ein Ziel erreicht wird [Lammenett, 2019, S.10].

Da alle im Rahmen dieser Arbeit definierten Metriken auf konkrete Ziele des Bildungsportals \textit{evaschiffmann.de} ausgerichtet sind, wird im weiteren Verlauf der Begriff KPI stellvertretend für alle verwendet. Dies dient in erster Linie der Lesbarkeit und verdeutlicht ebenfalls, dass übergeordnete Ziel, die Interaktionen der Nutzer mit dem Bildungsportal möglichst umfassend darzustellen.

In Zusammenarbeit mit der Professur für Geschichtsdidaktik wurden spezifische KPIs für das Bildungsportal \textit{evaschiffmann.de} entwickelt. Diese Indikatoren basieren auf den Gegebenheiten und dem Content der Unterseiten, um die Nutzungsmerkmale jeder Seite detailliert zu erfassen. Zudem wurden allgemeine KPIs definiert, welche für alle Unterseiten separat erhoben werden und einen Vergleich der Attraktivität der Seiten ermöglichen. Insgesamt sollen die KPIs eine umfassende Analyse des Nutzerverhaltens bieten und als Grundlage für die Bewertung der Zielerreichung dienen. KPIs, die für alle Unterseiten erfasst werden, sind in Tabelle~\ref{tab:kpi_allgemein} dargestellt:

\begin{table}[h]
    \centering
    \caption{Allgemeine KPIs für das Bildungsportal \textit{evaschiffmann.de}}
    \label{tab:kpi_allgemein}
    \renewcommand{\arraystretch}{1.5} % Erhöht die Zeilenhöhe
    \begin{tabularx}{\textwidth}{|X|X|X|}  
        \hline
        \textbf{KPI} & \textbf{Beschreibung} & \textbf{Berechnung} \\ \hline
        Anzahl Besucher & Anzahl der Nutzer, welche diese Webseite aufgerufen haben & {\footnotesize \(\text{Unique Visitors}\)} \\ \hline
        Verweildauer & Durchschnittliche Zeit, welche Nutzer auf der Webseite verbringen & 
        {\footnotesize \(\frac{\sum (\text{letzter Pageview} - \text{erster Pageview})}{\text{Anzahl der Sitzungen}}\)} \\ \hline
        Absprungrate & Anteil der Nutzer, welche die Website nach Aufruf dieser Webseite verlassen & 
        {\footnotesize \(\frac{\text{Sitzungen mit nur einer Seite}}{\text{Gesamtanzahl der Sitzungen}} \cdot 100\)} \\ \hline 
        Scrolltiefe & Wie tief scrollen Nutzer im Schnitt & 
        {\footnotesize \(\frac{\text{Gesamtscrollhöhe des Nutzers}}{\text{Gesamthöhe der Seite}} \cdot 100\)} \\ \hline
        Seitenaufrufe & Anzahl der aufgerufenen Seiten pro Sitzung & 
        {\footnotesize \(\frac{\sum \text{Pageviews}}{\text{Gesamtanzahl der Sitzungen}}\)} \\ \hline
    \end{tabularx}
\end{table}

Zusätzlich zu den in Tabelle~\ref{tab:kpi_uebersicht} dargestellten allgemeinen KPIs, die einen seitenübergreifenden Einblick in das Nutzungsverhalten ermöglichen, sind weitere seiten-spezifisch Indikatoren für die einzelnen Unterseiten des Bildungsportals definiert. Die in Tabelle~\ref{tab:kpi_allgemein} im Anhang aufgeführten Indikatoren liefern eine detaillierte Übersicht über die Gesamtaktivitäten der Nutzer auf der Website. Außerdem werden technische Merkmale und Informationen über die Nutzungsumgebung der Besucher erfasst. Für die Unterseite ``Zum Tagebuch'' werden die relevanten KPIs in Tabelle~\ref{tab:kpi_tagebuch} im Anhang dargestellt. Für die Unterseiten ``Wer war Eva Schiffmann?'' [Tabelle~\ref{tab:kpi_eva_schiffmann}], ``Themen'' [Tabelle~\ref{tab:kpi_themen}], ``Orte'' [Tabelle~\ref{tab:kpi_orte}] und ``Evas Lektüren'' [Tabelle~\ref{tab:kpi_evas_lektueren}] werden ebenfalls KPIs im Anhang abgebildet.


\section{Datenerfassung} % 2-2,5 Seiten

\subsection{Logfile-Analyse}
Logdateien (engl. Logfiles) gehören zu den ältesten Methoden, um Nutzungsdaten von Webseiten zu erfassen. Webserver protokollieren seit den Anfängen des Internets sämtliche Anfragen, die an sie gestellt werden, sowie die Antworten, die sie daraufhin liefern [Quelle Suchen]. Diese Protokolle werden in Form von Textdateien gespeichert und bieten eine strukturierte Übersicht über alle Interaktionen, auch „Hits“ genannt, die auf dem Server stattfinden. Die Erstellung von Logfiles erfolgt durch den Webserver, der alle Interaktionen zwischen Nutzer und Webseite aufzeichnet. Sobald ein Nutzer eine Webseite aufruft, sendet sein Browser mehrere Anforderungen (Requests) an den Server, um die verschiedenen Elemente der Seite wie Texte, Bilder oder Skripte zu laden. Der Server liefert daraufhin die angeforderten Inhalte zurück (Responses) und speichert diese Vorgänge zeitgleich in einer Logdatei. Diese Dateien, die in der Regel täglich neu generiert werden, dienen als Quelle für die Analyse von Zugriffen auf die Website. [Hassler, 2019, Kap. 2.2] 

Im Listing~\ref{lst:logfile} ist ein Beispiel eines Logfile-Eintrags im Common Logfile Format (CLF) zu sehen: 

\lstinputlisting[caption=Logfile-Eintrag im CLF {[Fou]}, label={lst:logfile}, language=Apache]{listings/logfile_entry.txt}

Aus diesem Beispiel Eintrag lassen sich folgende Informationen in entsprechender Reihenfolge entnehmen [Apache Software Foundation, o. D.?]: 

\begin{itemize}
    \item IP-Adresse des Aufrufenden
    \item Identitätskennzeichen
    \item Authentifizierter Benutzername
    \item Aufrufdatum und Zeit
    \item URL der aufgerufenen Datei
    \item HTTP-Anfrage
    \item Ergebnis des Aufrufs (Status)
    \item Größe der zurückgegebenen Datei
\end{itemize}

Zusätzlich wird in der Logfile auch die Aufrufmethode (z. B. GET oder POST),  gespeichert, diese Angabe ist jedoch für eine spätere Analyse oft weniger relevant [Hassler, 2019, Kap. 2.2]. Der Vorteil dieser Methode ist es, dass die Datenerfassung unabhängig von Client-Technologien abläuft, da diese serverseitig erfolgt und keine zusätzlichen Technologien wie JavaScript notwendig sind. Zudem werden sämtliche HTTP-Requests, einschließlich der von Bots und Suchmaschinen-Crawlern, erfasst und können leicht in Textform archiviert werden. [Ryte Wiki, o.D.]
Der große Nachteil dieses serverseitigen Verfahrens ist es, dass clientseitige Informationen, welche nicht an den Webserver übertragen werden, nicht erfasst werden können. Ebenso werden Interaktionen wie das Anklicken eines Bildes, die Scrolltiefe oder Verweildauer, die das Nutzerverhalten genauer beschreiben, nicht berücksichtigt. Zudem können Seitenaufrufe (engl. Page Views), welche aus dem Browser- Cache geladen werden, nicht in den Logfiles erfasst werden. Ein Verfahren, welches für dieses Problem abhilfe schafft und Nutzer einer Website nicht aus der Sicht des Servers, sondern aus Sicht des Clients betrachtet, ist das sogenannte Page Tagging. [COUNTER, 2021]

\subsection{Page Tagging}
\label{sec:pagetagging}
Unter Page Tagging versteht man die Einbindung eines kurzen Codeausschnittes (engl. Snippet) in den HTML-Code einer Webseite um Nutzerdaten zu erfassen. Dieses Snippet ist meistens in der Programmiersprache Javascript geschrieben. Das Snippet ermöglicht die Datenerfassung, indem es eine Javascript-Bibliothek herunterlädt, die im Cache-Speicher des Webbrowsers hinterlegt wird, um bei zukünftigen Seitenaufrufen schneller geladen zu werden. Nachdem das Page Tag die Bibliothek geladen hat, wird der Code ausgeführt, um verschiedene Daten aus dem Browser zu sammeln [Dykes, 2014, S.70-71]. Es können zum einen Daten abegerufen werden, welche per Browser Object Model (BOM) bezüglich der Einstellungen für den Webbrowser zu Verfügung stehen und zum anderen auch Informationen, welche das Document Object Model (DOM) enthält. Hierbei lassen sich unter anderem folgende Informationen per Page Tag sammeln [Hassler, 2019, Kap.2.3]:  

\begin{itemize}
    \item Mauszeigerposition
    \item Interaktionen mit Multimedia-Dateien
    \item Verweise in Form von Links
    \item Titel der Seite
    \item Tastatureingaben
    \item Bildschirmauflösung
    \item Cookies
    \item alle Informationen, welche auch Logfiles liefern
\end{itemize}

Um die gesammelten Daten an den Webserver zu übertragen, wird ein Bild in der Größe eines Pixels erzeugt, weshalb dieses Verfahren ebenfalls als Pixel-Tracking bezeichnet wird [Hassler, 2019, S.31]. Der Webbrowser erkennt dieses Bild als fehlenden Inhalt an, der geladen werden muss und sendet eine HTTP-Anfrage um es abzurufen. Diese Anfrage wird auch als Image-Request bezeichnet und enthält alle zuvor gesammelten Daten als Parameter in der URL (Uniform Resource Locator). Die Image-Request wird allerdings nicht an den Webserver gesendet, auf welchem die Website hinterlegt ist, sondern an einen dedizierten Datensammlungsserver. Wurden die Daten vom Datensammlungsserver empfangen werden die Parameter aus der URL extrahiert und in einer Datenbank gespeichert. Anschließend können die Daten von einer Analyse-Engine verarbeitet werden um zusätzliche Einsichten in das Nutzerverhalten zu gewinnen. Neben der Verarbeitung der Daten kann der Datensammlungsserver in der HTTP-Antwort auch einen Cookie setzen. Dieser Cookie enthält eine eindeutige Kennung (Visitor-ID), die es ermöglicht, dass Gerät des Nutzers bei zukünftigen Besuchen wiederzuerkennen und weitere Informationen mit diesem zu verknüpfen [Dykes, 2014, S.70-71].

- Grundlage von Page Tagging sind Events -> Quelle

\subsection{Events}
Ein Event beschreibt eine gezielte Aktion, die auf einer Webseite durch einen Nutzer ausgelöst wird. Diese Aktionen werden entweder vom Browser oder vom Server protokolliert und mit einem Zeitstempel versehen. Events können unter anderem das Einblenden von Werbeanzeigen, das Beginnen oder Abschließen von Kaufprozessen, Änderungen in Formularfeldern oder das Abspielen von Videos sein. [WAA, 2007, S.33]

Für das Bildungsportal \textit{evaschiffmann.de} spielen Events somit eine essenzielle Rolle, wenn es um die Erfassung von Interaktionen mit Video- und Audioelementen geht. Ebenso werden Events unter anderem genutzt, um KPIs zu berechnen, welche sich auf die Nutzung der Suchfunktion, die Interaktionen mit der Karte oder das aufklappen von Überschriften beziehen. Events werden ebenfalls für die Aufzeichnung von Interaktionen mit eingebetteten Links verwendet [AT Internet, o.D]. Wie zum Beispiel das anklicken von Links, welche zu einem bestimmten Tagebucheintrag führen.

\subsection{Datenschutz und rechtliche Anforderungen}
\label{sec:datenschutz}
Die Analyse der Logfiles und besonders das Page Tagging, bieten umfangreiche Möglichkeiten zur Erfassung von Nutzerdaten. Im Umgang mit diesen personenbezogenen Daten muss allerdings einiges beachtet werden, um den gesetzlichen Datenschutzanforderungen gerecht zu werden. Im Folgenden werden die rechtlichen Aspekte und deren Auswirkungen auf die Webanalyse näher beleuchtet.

Der Datenschutz ist ein übergeordnetes Konzept, das in verschiedenen Ländern auf unterschiedliche Art und Weise geregelt ist. Die DSGVO hingegen stellt eine spezifische gesetzliche Regelung der EU dar, die alle Mitgliedstaaten gleichermaßen betrifft. Während Datenschutz allgemein darauf abzielt, die Privatsphäre der Menschen zu schützen, legt die DSGVO detaillierte Anforderungen an den Umgang mit personenbezogenen Daten fest und sieht hohe Bußgelder bei Verstoßen vor. Insbesondere für international tätige Unternehmen ist die Einhaltung der DSGVO essenziell, da sie auch außerhalb der EU gilt, wenn Daten von EU-Bürgern verarbeitet werden (Voigt \& Von dem Bussche, 2017, Kap.1; Kap.2).

Nach Art. 4 Abs. 1 DSGVO gelten alle Informationen, die sich auf eine identifizierte oder identifizierbare natürliche Person beziehen, als personenbezogene Daten (Europäische Union, 2016, Art. 4 Abs. 1). Hierzu zählen somit auch IP-Adressen und Cookies [Hanschke, 2020, Kap.2.4].

Art. 6 Abs. 1 DSGVO gibt vor, dass die Verarbeitung personenbezogener Daten nur rechtmäßig ist, wenn sie auf einer rechtlichen Grundlage beruht. Im Kontext der Webanalyse ist häufig die Einwilligung (Art. 6 Abs. 1 lit. a) relevant, welche vor der Datenerhebung eingeholt werden muss. Alternativ kann ein berechtigtes Interesse des Verantwortlichen (Art. 6 Abs. 1 lit. f) geltend gemacht werden, sofern die Interessen der Nutzer gewahrt bleiben (Europäische Union, 2016).

Die rechtlichen Anforderungen der DSGVO haben direkte Auswirkungen auf die Gestaltung und den Betrieb der Webanalyse. Als wichtige Aspekte gelten: 

\begin{itemize}
    \item \textbf{Transparenz:} Nutzer müssen darüber informiert werden, welche Daten erfasst werden und zu welchem Zweck [Hanschke, 2020, Kap.2.4].
    \item \textbf{Datenminimierung:} Analysesysteme sollten nur die für den jeweiligen Zweck erforderlichen Daten sammeln [Europäische Union, 2016, Art. 5 Abs. 1 lit. c].
    \item \textbf{Einwilligung:} Die Verarbeitung personenbezogener Daten geschieht oft durch den Einsatz von Cookies. Hierzu muss die Einwilligung der Nutzer eingeholt werden [Europäische Union, 2016, Art. 6 Abs. 1 lit. a]. 
    \item \textbf{?Rechenschaftspflicht?:} Unternehmen müssen nachweisen können, dass sie die Anforderungen der DSGVO einhalten. Dies erfordert technische und organisatorische Maßnahmen wie Dokumentation und Auditierung (Voigt Von dem Bussche, 2017).
\end{itemize}

Die IP-Adresse wird von der DSGVO als personenbezogenes Datum eingestuft, da sie in Kombination mit weiteren Informationen eine Identifizierung der Person ermöglichen kann. Analytics-Systeme müssen daher besondere Maßnahmen ergreifen, um die Verarbeitung der IP-Adressen DSGVO-konform zu gestalten. Häufig wird die IP-Adresse anonymisiert, bevor sie gespeichert oder weiterverarbeitet wird. Google Analytics beispielsweise bietet eine Funktion zur IP-Anonymisierung, bei der die letzten Stellen der IP-Adresse entfernt werden (Google, o.D.). % noch quellen suchen + PostHog

Cookies spielen eine zentrale Rolle in der Webanalyse, da sie es ermöglichen, Nutzer über verschiedene Sitzungen hinweg zu identifizieren. Die Verwendung von Cookies unterliegt jedoch strengen Anforderungen. Gemäß der E-Privacy-Richtlinie ("Cookie-Richtlinie") und der DSGVO ist für den Einsatz von Cookies, die nicht technisch notwendig sind, eine ausdrückliche Einwilligung der Nutzer erforderlich (Europäische Union, 2016). % Quelle + PostHog

Zusätzlich müssen Nutzer die Möglichkeit haben, ihre Einwilligung jederzeit zu widerrufen. Dies stellt hohe Anforderungen an die technische Umsetzung von Cookie-Bannern und Consent-Management-Plattformen (Trepte, 2021).

\section{Tools zur Webanalyse} %3 Seiten
Es gibt eine überwältigende Anzahl von Webanalyse-Tools, welche sich in ihren Funktionen, Kosten und technischen Ansätzen erheblich unterscheiden [Böhm \& Rittberger, 2016, S.244]. Grundsätzlich ist das Page Tagging besser geeignet, um detaillierte Informationen über das Nutzerverhalten auf Webseiten zu erfassen [vgl. Hassler, 2019, Kap.2.5.3]. Logfiles hingegen wurden ursprünglich zur technischen Überwachung entwickelt und enthalten nicht die dafür erforderlichen Daten [vgl. Hassler, 2019, Kap.2.5.3]. Somit und mit den Erkenntnissen aus Kapitel~\ref{sec:pagetagging} wird deutlich, dass Page Tagging nicht nur umfangreiche Nutzerdaten liefert, sondern auch alle Informationen abdeckt, die durch die Analyse von Logfiles erfasst werden können. Weshalb bei der Auswahl einer Tool-Lösung ebenfalls darauf geachtet wird, dass die Daten per Page Tagging beziehungsweise per Events erhoben werden. 

Bei der Auswahl eines geeigneten Tools für das Bildungsportal \textit{evaschiffmann.de} wurden daher die folgenden Kriterien berücksichtigt [vgl. Matomo, o.D.; CiteUp, 2024; Hassler, 2019, Kap.1.6]:

\begin{itemize}
    \item \textbf{Kosten:} Zunächst soll die kostenlose Variante eines Tools implementiert werden, um die grundlegenden Funktionen und die Eignung für das Bildungsportal zu testen, ohne dabei sofort finanzielle Mittel aufzuwenden.
    \item \textbf{Integration in TYPO3:} Ebenfalls ist darauf zu achten, dass das Bildungsportal mithilfe des Content-Management-Systems (CMS) TYPO3 implementiert wurde. Daher ist bei der Auswahl des Webanalyse-Tools wichtig, sicherzustellen, dass eine Integration in TYPO3 möglich ist.
    \item \textbf{Funktionsumfang:} Das Tool muss grundsätzlich in der Lage sein, alle KPIs für das Bildungsportal zu erfassen. Da für manche KPIs eigene Events definiert werden müssen, muss das Tool diese Möglichkeit ebenfalls bieten. 
    \item \textbf{Dokumentation:} Um die Implementierung zu erleichtern ist eine ausführliche Dokumentation entscheidened.
    \item \textbf{Datengenauigkeit:} Es soll ein Tool ausgewählt werden, welches Datenaktualisierung in Echtzeit bietet um eine unverfälschte Basis für datengetriebene Entscheidungen zu gewährleisten. Ungenauigkeiten können sonst zu fehlerhaften Schlussfolgerungen führen.
    \item \textbf{Datenschutz und DSGVO-Konformität:} Wie in Kapitel~\ref{sec:datenschutz} erläutert, sind Datenschutz und die Einhaltung der DSGVO grundlegende Anforderungen an ein Webanalyse-Tool. Somit sollte dieses in der Lage sein, die geltenden Datenschutzgesätze einzuhalten.
\end{itemize}

Google Analytics ist mit einem Marktanteil von 82,0 \% unter den Websites, die Webanalyse-Tools verwenden, das mit Abstand am weitesten verbreitete Tool [W3Techs, 2025]. GA hat allerdings insbesondere in Europa stark an Akzeptanz verloren, da es wiederholt in Konflikt mit den Vorgaben der DSGVO geraten ist. Seit dem Ende des EU-US Privacy Shield ist die rechtliche Grundlage für die Übertragung von Nutzerdaten in die USA weggefallen, was dazu führte, dass Google Analytics mehrfach als nicht datenschutzkonform eingestuft wurde. [vgl. Förster, 2024]

Auf grundlage dessen ist es keine Option GA für das Sammeln von Nutzerdaten auf dem Bildungsportal zu verwenden. Ein Tool welches die DSGVO-konforme Datenerhebung ermöglicht ist PostHog [vgl. Förster, 2024]. 
